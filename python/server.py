#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é’‰é’‰æ–‡æ¡£è§£æ MCP æœåŠ¡å™¨
æä¾›é’‰é’‰æ–‡æ¡£å†…å®¹æå–ã€è§£æå’ŒHTMLç”ŸæˆåŠŸèƒ½
"""

from typing import Annotated, Optional, Dict, Any, List
import os
import json
import asyncio
import re
import html as html_module
import random
import urllib3
from pathlib import Path
from dataclasses import dataclass

import httpx
from mcp.shared.exceptions import McpError
from mcp.server import Server
from mcp.server.stdio import stdio_server
from mcp.types import (
    ErrorData,
    GetPromptResult,
    Prompt,
    PromptArgument,
    PromptMessage,
    TextContent,
    Tool,
    INVALID_PARAMS,
    INTERNAL_ERROR,
)
from pydantic import BaseModel, Field
from bs4 import BeautifulSoup
import hashlib
import mimetypes

# ç¦ç”¨SSLè­¦å‘Š
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# ==================== å¸¸é‡å®šä¹‰ ====================
BASE_URL = "https://alidocs.dingtalk.com"
API_DOCUMENT_DATA = f"{BASE_URL}/api/document/data"
USER_AGENT = "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/141.0.0.0 Safari/537.36"
DEFAULT_TIMEOUT = 30.0

# HTTPè¯·æ±‚é€šç”¨Headers
COMMON_HEADERS = {
    "accept-encoding": "gzip, deflate, br, zstd",
    "accept-language": "zh-CN,zh;q=0.9,en-US;q=0.8,en;q=0.7",
    "user-agent": USER_AGENT,
}

# ä»£ç è¯­è¨€æ˜ å°„
CODE_LANGUAGE_MAP = {
    'text/x-java': 'java',
    'text/x-python': 'python',
    'text/x-javascript': 'javascript',
    'text/x-go': 'go',
    'text/x-c++': 'cpp',
    'text/x-sql': 'sql',
    'text/x-sh': 'bash',
    'text/plain': 'text',
    'application/json': 'json',
    'text/html': 'html',
    'text/css': 'css'
}

# ä»ç¯å¢ƒå˜é‡è·å–é’‰é’‰Cookie
DINGTALK_COOKIE = os.getenv("DINGTALK_COOKIE")


# ==================== æ•°æ®æ¨¡å‹ ====================
@dataclass
class DocumentResult:
    """æ–‡æ¡£è§£æç»“æœ"""
    node_id: str
    dentry_key: str
    mainsite_content: Optional[Dict[str, Any]] = None
    document_data: Optional[Dict[str, Any]] = None
    content: Optional[Dict[str, Any]] = None
    html: Optional[str] = None
    output_dir: Optional[str] = None


class DingTalkDocRequest(BaseModel):
    """é’‰é’‰æ–‡æ¡£è¯·æ±‚å‚æ•°"""
    url_or_node_id: Annotated[
        str,
        Field(description="é’‰é’‰æ–‡æ¡£çš„å®Œæ•´URLæˆ–NODE_ID")
    ]
    cookie: Annotated[
        Optional[str],
        Field(description="é’‰é’‰ç™»å½•Cookieï¼ˆå¯é€‰ï¼Œæœªæä¾›åˆ™ä½¿ç”¨ç¯å¢ƒå˜é‡ï¼‰", default=None)
    ]
    save_files: Annotated[
        Optional[bool],
        Field(description="æ˜¯å¦ä¿å­˜ä¸­é—´æ–‡ä»¶", default=True)
    ]
    output_dir: Annotated[
        Optional[str],
        Field(description="è¾“å‡ºç›®å½•è·¯å¾„ï¼ˆå¯é€‰ï¼‰", default=None)
    ]


class DingTalkDocParseRequest(BaseModel):
    """é’‰é’‰æ–‡æ¡£è§£æå‚æ•°ï¼ˆä»…ç”ŸæˆHTMLï¼‰"""
    url_or_node_id: Annotated[
        str,
        Field(description="é’‰é’‰æ–‡æ¡£çš„å®Œæ•´URLæˆ–NODE_ID")
    ]
    cookie: Annotated[
        Optional[str],
        Field(description="é’‰é’‰ç™»å½•Cookieï¼ˆå¯é€‰ï¼Œæœªæä¾›åˆ™ä½¿ç”¨ç¯å¢ƒå˜é‡ï¼‰", default=None)
    ]


# ==================== å·¥å…·å‡½æ•° ====================
def check_cookie(cookie: Optional[str] = None) -> str:
    """
    æ£€æŸ¥å¹¶è¿”å›æœ‰æ•ˆçš„Cookie
    
    Args:
        cookie: å¯é€‰çš„Cookieå­—ç¬¦ä¸²ï¼Œå¦‚æœæœªæä¾›åˆ™ä½¿ç”¨ç¯å¢ƒå˜é‡
        
    Returns:
        æœ‰æ•ˆçš„Cookieå­—ç¬¦ä¸²
        
    Raises:
        McpError: å½“Cookieä¸å­˜åœ¨æ—¶
    """
    final_cookie = cookie or DINGTALK_COOKIE
    if not final_cookie:
        raise McpError(ErrorData(
            code=INTERNAL_ERROR,
            message="ç¼ºå°‘é’‰é’‰Cookieã€‚è¯·é€šè¿‡å‚æ•°ä¼ é€’æˆ–è®¾ç½®ç¯å¢ƒå˜é‡ DINGTALK_COOKIE"
        ))
    return final_cookie


def extract_node_id_from_url(url_or_node_id: str) -> str:
    """
    ä»å®Œæ•´URLä¸­æå–node_idï¼Œå¦‚æœå·²ç»æ˜¯node_idåˆ™ç›´æ¥è¿”å›
    
    Args:
        url_or_node_id: é’‰é’‰æ–‡æ¡£çš„å®Œæ•´URLæˆ–NODE_ID
        
    Returns:
        æå–çš„node_id
        
    Raises:
        ValueError: å½“æ— æ³•ä»URLä¸­æå–node_idæ—¶
    """
    if url_or_node_id.startswith('http'):
        match = re.search(r'/i/nodes/([^?/]+)', url_or_node_id)
        if match:
            return match.group(1)
        raise ValueError(f"æ— æ³•ä»URLä¸­æå–node_id: {url_or_node_id}")
    return url_or_node_id


# ==================== HTTPè¯·æ±‚å‡½æ•° ====================
async def fetch_node_by_get(node_id: str, cookie: str) -> str:
    """
    é€šè¿‡GETè¯·æ±‚è·å–é’‰é’‰æ–‡æ¡£èŠ‚ç‚¹æ•°æ®
    
    Args:
        node_id: æ–‡æ¡£èŠ‚ç‚¹ID
        cookie: é’‰é’‰ç™»å½•Cookie
        
    Returns:
        HTMLå“åº”æ–‡æœ¬
        
    Raises:
        McpError: å½“HTTPè¯·æ±‚å¤±è´¥æ—¶
    """
    url = f"{BASE_URL}/i/nodes/{node_id}"
    
    headers = {
        **COMMON_HEADERS,
        "authority": "alidocs.dingtalk.com",
        "method": "GET",
        "scheme": "https",
        "accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8",
        "cookie": cookie,
    }
    
    async with httpx.AsyncClient(verify=False, timeout=DEFAULT_TIMEOUT) as client:
        try:
            response = await client.get(url, headers=headers, params={"rnd": random.random()})
            response.raise_for_status()
            return response.text
        except httpx.HTTPError as e:
            raise McpError(ErrorData(
                code=INTERNAL_ERROR,
                message=f"GETè¯·æ±‚å¤±è´¥: {str(e)}"
            ))


async def fetch_document_data(cookie: str, dentry_key: str) -> Dict[str, Any]:
    """
    è·å–é’‰é’‰æ–‡æ¡£æ•°æ®ï¼ˆPOSTè¯·æ±‚ï¼‰
    
    Args:
        cookie: é’‰é’‰ç™»å½•Cookie
        dentry_key: æ–‡æ¡£entry key
        
    Returns:
        æ–‡æ¡£æ•°æ®å­—å…¸
        
    Raises:
        McpError: å½“HTTPè¯·æ±‚å¤±è´¥æ—¶
    """
    headers = {
        **COMMON_HEADERS,
        "authority": "alidocs.dingtalk.com",
        "a-dentry-key": dentry_key,
        "accept": "*/*",
        "content-type": "application/json",
        "cookie": cookie,
        "origin": BASE_URL,
    }
    
    payload = {"fetchBody": True}
    
    async with httpx.AsyncClient(verify=False, timeout=DEFAULT_TIMEOUT) as client:
        try:
            response = await client.post(API_DOCUMENT_DATA, headers=headers, json=payload)
            response.raise_for_status()
            return response.json()
        except httpx.HTTPError as e:
            raise McpError(ErrorData(
                code=INTERNAL_ERROR,
                message=f"POSTè¯·æ±‚å¤±è´¥: {str(e)}"
            ))


async def download_image(url: str, cookie: str, output_dir: Path) -> Optional[str]:
    """
    ä¸‹è½½å›¾ç‰‡å¹¶ä¿å­˜åˆ°æœ¬åœ°
    
    Args:
        url: å›¾ç‰‡URL
        cookie: é’‰é’‰ç™»å½•Cookie
        output_dir: è¾“å‡ºç›®å½•è·¯å¾„
        
    Returns:
        æœ¬åœ°å›¾ç‰‡è·¯å¾„ï¼ˆç›¸å¯¹äºHTMLæ–‡ä»¶çš„è·¯å¾„ï¼‰ï¼Œå¦‚æœä¸‹è½½å¤±è´¥åˆ™è¿”å›None
    """
    if not url:
        return None
    
    # ç¡®ä¿å›¾ç‰‡ç›®å½•å­˜åœ¨
    images_dir = output_dir / "images"
    images_dir.mkdir(exist_ok=True)
    
    try:
        # æ„å»ºå®Œæ•´çš„URL
        original_url = url
        if not url.startswith('http'):
            url = f'{BASE_URL}{url}'
        
        # ç”Ÿæˆæ–‡ä»¶åï¼ˆä½¿ç”¨åŸå§‹URLçš„hashå€¼ï¼Œç¡®ä¿ä¸€è‡´æ€§ï¼‰
        url_hash = hashlib.md5(original_url.encode()).hexdigest()
        
        # ä¸‹è½½å›¾ç‰‡
        headers = {
            **COMMON_HEADERS,
            "authority": "alidocs.dingtalk.com",
            "accept": "image/avif,image/webp,image/apng,image/svg+xml,image/*,*/*;q=0.8",
            "referer": f"{BASE_URL}/",
            "cookie": cookie,
        }
        
        async with httpx.AsyncClient(
            verify=False, 
            timeout=DEFAULT_TIMEOUT,
            follow_redirects=True  # æ˜ç¡®å¯ç”¨é‡å®šå‘è·Ÿéš
        ) as client:
            response = await client.get(url, headers=headers)
            response.raise_for_status()
            
            # ä»å“åº”å¤´è·å–Content-Typeæ¥ç¡®å®šæ–‡ä»¶æ‰©å±•å
            ext = None
            content_type = response.headers.get('content-type', '')
            if content_type:
                ext = mimetypes.guess_extension(content_type.split(';')[0].strip())
            
            # å¦‚æœæ— æ³•ä»Content-Typeè·å–ï¼Œå°è¯•ä»æœ€ç»ˆURLè·å–
            if not ext:
                final_url = str(response.url)  # è·å–é‡å®šå‘åçš„æœ€ç»ˆURL
                parsed_url = final_url.split('?')[0]  # ç§»é™¤æŸ¥è¯¢å‚æ•°
                ext = mimetypes.guess_extension(mimetypes.guess_type(parsed_url)[0] or 'image/jpeg')
            
            # å¦‚æœè¿˜æ˜¯æ— æ³•ç¡®å®šï¼Œä½¿ç”¨é»˜è®¤æ‰©å±•å
            if not ext:
                ext = '.jpg'
            
            filename = f"{url_hash}{ext}"
            file_path = images_dir / filename
            
            # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œç›´æ¥è¿”å›è·¯å¾„
            if file_path.exists():
                return f"images/{filename}"
            
            # ä¿å­˜å›¾ç‰‡
            with open(file_path, 'wb') as f:
                f.write(response.content)
            
            return f"images/{filename}"
            
    except Exception as e:
        # ä¸‹è½½å¤±è´¥æ—¶è¿”å›Noneï¼Œä½¿ç”¨åŸå§‹URL
        print(f"ä¸‹è½½å›¾ç‰‡å¤±è´¥ {url}: {str(e)}")
        return None


# ==================== æ•°æ®æå–å‡½æ•° ====================
def extract_mainsite_content(html: str) -> Dict[str, Any]:
    """
    ä»HTMLä¸­æå–mainsite_server_contentçš„JSONæ•°æ®
    
    Args:
        html: HTMLé¡µé¢å†…å®¹
        
    Returns:
        è§£æåçš„JSONæ•°æ®å­—å…¸
        
    Raises:
        McpError: å½“æ— æ³•æ‰¾åˆ°æˆ–è§£æJSONæ•°æ®æ—¶
    """
    soup = BeautifulSoup(html, 'html.parser')
    script = soup.find('script', {'id': 'mainsite_server_content'})
    
    if not script or not script.string:
        raise McpError(ErrorData(
            code=INTERNAL_ERROR,
            message="æœªæ‰¾åˆ°mainsite_server_content"
        ))
    
    try:
        return json.loads(script.string.strip())
    except json.JSONDecodeError as e:
        raise McpError(ErrorData(
            code=INTERNAL_ERROR,
            message=f"JSONè§£æå¤±è´¥: {str(e)}"
        ))


def extract_document_content(document_data: Dict[str, Any]) -> Optional[Dict[str, Any]]:
    """
    ä»document_dataä¸­æå–æ–‡æ¡£å†…å®¹
    
    Args:
        document_data: æ–‡æ¡£æ•°æ®å­—å…¸
        
    Returns:
        æ–‡æ¡£å†…å®¹å­—å…¸ï¼Œå¦‚æœæ— æ³•æå–åˆ™è¿”å›None
    """
    if not document_data:
        return None
    
    try:
        # æ–¹å¼1: ç›´æ¥ä»JSONä¸­è·å–content
        content_str = document_data['data']['documentContent']['checkpoint']['content']
        return json.loads(content_str)
    except (KeyError, json.JSONDecodeError):
        # æ–¹å¼2: OSSåŠ å¯†å­˜å‚¨ï¼ˆæš‚ä¸æ”¯æŒå®Œæ•´è§£å¯†ï¼‰
        return None


def extract_dentry_key(mainsite_content: Dict[str, Any]) -> str:
    """
    ä»mainsite_contentä¸­æå–dentryKey
    
    Args:
        mainsite_content: mainsiteå†…å®¹å­—å…¸
        
    Returns:
        dentryKeyå­—ç¬¦ä¸²
        
    Raises:
        McpError: å½“æ— æ³•æ‰¾åˆ°dentryKeyæ—¶
    """
    # å°è¯•ä»dentryInfoä¸­è·å–
    if 'dentryInfo' in mainsite_content and 'data' in mainsite_content['dentryInfo']:
        dentry_key = mainsite_content['dentryInfo']['data'].get('dentryKey')
        if dentry_key:
            return dentry_key
    
    # å°è¯•ä»dataä¸­è·å–nodeId
    dentry_key = mainsite_content.get('data', {}).get('nodeId')
    if dentry_key:
        return dentry_key
    
    raise McpError(ErrorData(
        code=INTERNAL_ERROR,
        message="æœªæ‰¾åˆ°dentryKeyæˆ–nodeId"
    ))


# ==================== HTMLè§£æå‡½æ•° ====================
def parse_code_block(code_elem: List[Any]) -> str:
    """
    è§£æä»£ç å—å…ƒç´ 
    
    Args:
        code_elem: ä»£ç å—å…ƒç´ åˆ—è¡¨
        
    Returns:
        HTMLæ ¼å¼çš„ä»£ç å—å­—ç¬¦ä¸²
    """
    if not isinstance(code_elem, list) or len(code_elem) < 2 or code_elem[0] != 'code':
        return ''
    
    attrs = code_elem[1] if len(code_elem) > 1 else {}
    syntax = attrs.get('syntax', 'text/plain')
    code = attrs.get('code', '')
    
    if not code:
        return ''
    
    # è·å–è¯­è¨€æ ‡è¯†
    language = CODE_LANGUAGE_MAP.get(syntax, syntax.replace('text/x-', '').replace('text/', ''))
    code_escaped = html_module.escape(code)
    
    return f'''<div class="code-block">
    <div class="code-header">
        <span class="code-language">{language}</span>
        <button class="code-copy" onclick="copyCode(this)" title="å¤åˆ¶ä»£ç ">ğŸ“‹ å¤åˆ¶</button>
    </div>
    <pre><code class="language-{language}">{code_escaped}</code></pre>
</div>'''


def parse_text_style(style_obj: Dict[str, Any]) -> str:
    """
    è§£ææ–‡æœ¬æ ·å¼
    
    Args:
        style_obj: æ ·å¼å¯¹è±¡å­—å…¸
        
    Returns:
        CSSæ ·å¼å­—ç¬¦ä¸²
    """
    styles = []
    if style_obj.get('bold'):
        styles.append('font-weight: bold')
    if style_obj.get('color'):
        styles.append(f'color: {style_obj["color"]}')
    if style_obj.get('sz') and style_obj.get('szUnit'):
        styles.append(f'font-size: {style_obj["sz"]}{style_obj["szUnit"]}')
    return '; '.join(styles) if styles else ''


def parse_span(span_elem: List[Any]) -> str:
    """
    è§£æspanå…ƒç´ 
    
    Args:
        span_elem: spanå…ƒç´ åˆ—è¡¨
        
    Returns:
        HTMLæ ¼å¼çš„spanå­—ç¬¦ä¸²
    """
    if not isinstance(span_elem, list) or len(span_elem) < 2 or span_elem[0] != 'span':
        return ''
    
    attrs = span_elem[1] if len(span_elem) > 1 else {}
    html_parts = []
    
    for i in range(2, len(span_elem)):
        child = span_elem[i]
        if isinstance(child, str):
            text = child.replace('\n', '<br>')
            if text:
                style = parse_text_style(attrs)
                html_parts.append(f'<span style="{style}">{text}</span>' if style else text)
        elif isinstance(child, list):
            html_parts.append(parse_span(child))
    
    return ''.join(html_parts)


def collect_image_urls(content: Dict[str, Any]) -> set:
    """
    æ”¶é›†æ–‡æ¡£ä¸­æ‰€æœ‰å›¾ç‰‡URL
    
    Args:
        content: æ–‡æ¡£å†…å®¹å­—å…¸
        
    Returns:
        å›¾ç‰‡URLé›†åˆ
    """
    image_urls = set()
    
    def _traverse(elem):
        if isinstance(elem, list) and len(elem) > 0:
            if elem[0] == 'img' and len(elem) > 1:
                attrs = elem[1] if isinstance(elem[1], dict) else {}
                src = attrs.get('src', '')
                if src:
                    # æ„å»ºå®Œæ•´URL
                    if not src.startswith('http'):
                        src = f'{BASE_URL}{src}'
                    image_urls.add(src)
            else:
                # é€’å½’éå†å­å…ƒç´ 
                for item in elem:
                    _traverse(item)
        elif isinstance(elem, dict):
            for value in elem.values():
                _traverse(value)
    
    if content:
        main_key = content.get('main')
        if main_key:
            parts = content.get('parts', {})
            main_part = parts.get(main_key, {})
            data = main_part.get('data', {})
            body = data.get('body', [])
            _traverse(body)
    
    return image_urls


def parse_image(img_elem: List[Any], image_url_map: Optional[Dict[str, str]] = None) -> str:
    """
    è§£æå›¾ç‰‡å…ƒç´ 
    
    Args:
        img_elem: å›¾ç‰‡å…ƒç´ åˆ—è¡¨
        image_url_map: å›¾ç‰‡URLåˆ°æœ¬åœ°è·¯å¾„çš„æ˜ å°„
        
    Returns:
        HTMLæ ¼å¼çš„å›¾ç‰‡å­—ç¬¦ä¸²
    """
    if not isinstance(img_elem, list) or len(img_elem) < 2 or img_elem[0] != 'img':
        return ''
    
    attrs = img_elem[1] if len(img_elem) > 1 else {}
    src = attrs.get('src', '')
    name = attrs.get('name', 'å›¾ç‰‡')
    width = attrs.get('width', 'auto')
    
    if not src:
        return f'<p style="color: #999;">[å›¾ç‰‡: {name}]</p>'
    
    # æ„å»ºå®Œæ•´URLç”¨äºæŸ¥æ‰¾æ˜ å°„
    original_src = src
    if not src.startswith('http'):
        full_url = f'{BASE_URL}{src}'
    else:
        full_url = src
    
    # å¦‚æœæœ‰æ˜ å°„ï¼Œä½¿ç”¨æœ¬åœ°è·¯å¾„
    if image_url_map and full_url in image_url_map:
        src = image_url_map[full_url]
    else:
        # å¦‚æœæ²¡æœ‰æ˜ å°„ï¼Œè¯´æ˜å›¾ç‰‡ä¸‹è½½å¤±è´¥æˆ–æœªä¸‹è½½
        # ä½¿ç”¨åŸå§‹URLï¼ˆå¯èƒ½éœ€è¦Cookieï¼Œæµè§ˆå™¨å¯èƒ½æ— æ³•æ˜¾ç¤ºï¼‰
        if not src.startswith('http'):
            src = f'{BASE_URL}{original_src}'
        # å¦‚æœä¸‹è½½å¤±è´¥ä¸”æœ‰æ˜ å°„è¡¨ï¼ˆè¯´æ˜å°è¯•è¿‡ä¸‹è½½ï¼‰ï¼Œæ˜¾ç¤ºæç¤º
        if image_url_map is not None:
            return f'<div class="image-container"><p style="color: #999; padding: 1rem; border: 1px dashed #ddd; border-radius: 4px;">[å›¾ç‰‡ä¸‹è½½å¤±è´¥: {name}]<br><small>åŸå§‹é“¾æ¥: <a href="{src}" target="_blank">{src[:50]}...</a></small></p></div>'
    
    return f'<div class="image-container"><img src="{src}" alt="{name}" style="max-width: {width}px; height: auto;" loading="lazy" /></div>'


def parse_paragraph(para_elem: List[Any], image_url_map: Optional[Dict[str, str]] = None) -> str:
    """
    è§£ææ®µè½å…ƒç´ 
    
    Args:
        para_elem: æ®µè½å…ƒç´ åˆ—è¡¨
        image_url_map: å›¾ç‰‡URLåˆ°æœ¬åœ°è·¯å¾„çš„æ˜ å°„
        
    Returns:
        HTMLæ ¼å¼çš„æ®µè½å­—ç¬¦ä¸²
    """
    if not isinstance(para_elem, list) or len(para_elem) < 2:
        return ''
    
    tag = para_elem[0]
    
    if tag == 'p':
        content_parts = []
        for i in range(2, len(para_elem)):
            child = para_elem[i]
            if isinstance(child, list) and len(child) > 0:
                if child[0] == 'img':
                    content_parts.append(parse_image(child, image_url_map))
                else:
                    content_parts.append(parse_span(child))
            elif isinstance(child, str):
                content_parts.append(child)
        
        paragraph_html = ''.join(content_parts)
        if not paragraph_html.strip():
            paragraph_html = '&nbsp;'
        
        return f'<p>{paragraph_html}</p>'
    
    if tag == 'img':
        return parse_image(para_elem, image_url_map)
    
    return ''


def parse_table(table_elem: List[Any]) -> str:
    """
    è§£æè¡¨æ ¼å…ƒç´ 
    
    Args:
        table_elem: è¡¨æ ¼å…ƒç´ åˆ—è¡¨
        
    Returns:
        HTMLæ ¼å¼çš„è¡¨æ ¼å­—ç¬¦ä¸²
    """
    if not isinstance(table_elem, list) or len(table_elem) < 2 or table_elem[0] != 'table':
        return ''
    
    rows_html = []
    for i in range(2, len(table_elem)):
        child = table_elem[i]
        if isinstance(child, list) and len(child) > 0 and child[0] == 'tr':
            row_html = parse_table_row(child)
            if row_html:
                rows_html.append(row_html)
    
    if not rows_html:
        return ''
    
    return f'''<div class="table-container">
    <table class="doc-table">
        {''.join(rows_html)}
    </table>
</div>'''


def parse_table_row(tr_elem: List[Any]) -> str:
    """
    è§£æè¡¨æ ¼è¡Œ
    
    Args:
        tr_elem: è¡¨æ ¼è¡Œå…ƒç´ åˆ—è¡¨
        
    Returns:
        HTMLæ ¼å¼çš„è¡¨æ ¼è¡Œå­—ç¬¦ä¸²
    """
    if not isinstance(tr_elem, list) or len(tr_elem) < 2 or tr_elem[0] != 'tr':
        return ''
    
    cells_html = []
    for i in range(2, len(tr_elem)):
        child = tr_elem[i]
        if isinstance(child, list) and len(child) > 0 and child[0] == 'tc':
            cell_html = parse_table_cell(child)
            if cell_html:
                cells_html.append(cell_html)
    
    if not cells_html:
        return ''
    
    return f'<tr>{"".join(cells_html)}</tr>'


def parse_table_cell(tc_elem: List[Any]) -> str:
    """
    è§£æè¡¨æ ¼å•å…ƒæ ¼
    
    Args:
        tc_elem: è¡¨æ ¼å•å…ƒæ ¼å…ƒç´ åˆ—è¡¨
        
    Returns:
        HTMLæ ¼å¼çš„è¡¨æ ¼å•å…ƒæ ¼å­—ç¬¦ä¸²
    """
    if not isinstance(tc_elem, list) or len(tc_elem) < 2 or tc_elem[0] != 'tc':
        return ''
    
    attrs = tc_elem[1] if len(tc_elem) > 1 else {}
    row_span = attrs.get('rowSpan', 1)
    col_span = attrs.get('colSpan', 1)
    fill = attrs.get('fill', '')
    v_align = attrs.get('vAlign', 'top')
    
    styles = []
    if fill:
        styles.append(f'background-color: {fill}')
    if v_align:
        styles.append(f'vertical-align: {v_align}')
    
    style_str = f' style="{"; ".join(styles)}"' if styles else ''
    
    content_parts = []
    for i in range(2, len(tc_elem)):
        child = tc_elem[i]
        if isinstance(child, list) and len(child) > 0 and child[0] == 'p':
            p_content = []
            for j in range(2, len(child)):
                p_child = child[j]
                if isinstance(p_child, list):
                    p_content.append(parse_span(p_child))
                elif isinstance(p_child, str):
                    p_content.append(p_child)
            content_parts.append(''.join(p_content))
    
    cell_content = '<br>'.join(content_parts) if content_parts else '&nbsp;'
    
    rowspan_attr = f' rowspan="{row_span}"' if row_span > 1 else ''
    colspan_attr = f' colspan="{col_span}"' if col_span > 1 else ''
    
    return f'<td{rowspan_attr}{colspan_attr}{style_str}>{cell_content}</td>'


# ==================== HTMLç”Ÿæˆå‡½æ•° ====================
def generate_html_from_content(
    content: Dict[str, Any], 
    doc_title: str = "é’‰é’‰æ–‡æ¡£",
    image_url_map: Optional[Dict[str, str]] = None
) -> Optional[str]:
    """
    ä»contentç”ŸæˆHTML
    
    Args:
        content: æ–‡æ¡£å†…å®¹å­—å…¸
        doc_title: æ–‡æ¡£æ ‡é¢˜
        image_url_map: å›¾ç‰‡URLåˆ°æœ¬åœ°è·¯å¾„çš„æ˜ å°„
        
    Returns:
        HTMLå­—ç¬¦ä¸²ï¼Œå¦‚æœæ— æ³•ç”Ÿæˆåˆ™è¿”å›None
        
    Raises:
        McpError: å½“ç”ŸæˆHTMLå¤±è´¥æ—¶
    """
    if not content:
        return None
    
    try:
        main_key = content.get('main')
        if not main_key:
            return None
        
        parts = content.get('parts', {})
        main_part = parts.get(main_key, {})
        data = main_part.get('data', {})
        body = data.get('body', [])
        
        html_parts = []
        for item in body[2:]:
            if not isinstance(item, list) or len(item) == 0:
                continue
            
            tag = item[0]
            # æ ¹æ®æ ‡ç­¾ç±»å‹é€‰æ‹©è§£æå‡½æ•°
            parser_map = {
                'table': parse_table,
                'code': parse_code_block,
                'p': lambda x: parse_paragraph(x, image_url_map),
                'img': lambda x: parse_image(x, image_url_map),
            }
            
            parser = parser_map.get(tag, lambda x: parse_paragraph(x, image_url_map))
            parsed_html = parser(item)
            if parsed_html:
                html_parts.append(parsed_html)
        
        content_html = '\n'.join(html_parts)
        
        html_template = f"""<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{doc_title}</title>
    <style>
        * {{ margin: 0; padding: 0; box-sizing: border-box; }}
        body {{
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'PingFang SC', sans-serif;
            line-height: 1.6;
            color: #333;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            padding: 2rem;
        }}
        .container {{ max-width: 900px; margin: 0 auto; background: white; border-radius: 12px; 
                      box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3); overflow: hidden; }}
        .header {{ background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; 
                   padding: 2rem; text-align: center; }}
        .header h1 {{ font-size: 2rem; font-weight: 600; margin-bottom: 0.5rem; }}
        .content {{ padding: 2rem 3rem; }}
        .content p {{ margin-bottom: 1rem; font-size: 1rem; line-height: 1.8; }}
        .table-container {{ margin: 1.5rem 0; overflow-x: auto; }}
        .doc-table {{ width: 100%; border-collapse: collapse; margin: 1rem 0; background: white; 
                      box-shadow: 0 2px 4px rgba(0,0,0,0.1); }}
        .doc-table td {{ border: 1px solid #ddd; padding: 0.75rem; font-size: 0.95rem; }}
        .doc-table tr:hover {{ background-color: #f5f5f5; }}
        .image-container {{ margin: 1.5rem 0; text-align: center; }}
        .image-container img {{ max-width: 100%; height: auto; border-radius: 8px; 
                                box-shadow: 0 4px 12px rgba(0,0,0,0.15); }}
        .code-block {{ margin: 1.5rem 0; border-radius: 8px; overflow: hidden; background: #282c34; 
                       box-shadow: 0 4px 12px rgba(0,0,0,0.15); }}
        .code-header {{ background: #21252b; padding: 0.5rem 1rem; display: flex; 
                        justify-content: space-between; align-items: center; }}
        .code-language {{ color: #61dafb; font-size: 0.85rem; font-weight: 600; text-transform: uppercase; }}
        .code-copy {{ background: #61dafb; color: #282c34; border: none; padding: 0.25rem 0.75rem; 
                      border-radius: 4px; cursor: pointer; font-size: 0.85rem; }}
        .code-copy:hover {{ background: #4fa8c5; }}
        .code-block pre {{ margin: 0; padding: 1rem; overflow-x: auto; background: #282c34; }}
        .code-block code {{ font-family: 'Monaco', 'Menlo', 'Consolas', monospace; font-size: 0.9rem; 
                            line-height: 1.6; color: #abb2bf; display: block; white-space: pre; }}
        .footer {{ text-align: center; padding: 1.5rem; background: #f8f9fa; color: #666; 
                   font-size: 0.85rem; border-top: 1px solid #e9ecef; }}
    </style>
    <script>
        function copyCode(button) {{
            const codeBlock = button.closest('.code-block');
            const code = codeBlock.querySelector('code').textContent;
            navigator.clipboard.writeText(code).then(() => {{
                const originalText = button.textContent;
                button.textContent = 'âœ“ å·²å¤åˆ¶';
                button.style.background = '#52c41a';
                setTimeout(() => {{
                    button.textContent = originalText;
                    button.style.background = '#61dafb';
                }}, 2000);
            }});
        }}
    </script>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>{doc_title}</h1>
            <div class="meta">é’‰é’‰æ–‡æ¡£å†…å®¹è§£æ</div>
        </div>
        <div class="content">
{content_html}
        </div>
        <div class="footer">
            ç”±é’‰é’‰æ–‡æ¡£è§£æMCPæœåŠ¡ç”Ÿæˆ | Powered by Python
        </div>
    </div>
</body>
</html>"""
        
        return html_template
        
    except Exception as e:
        raise McpError(ErrorData(
            code=INTERNAL_ERROR,
            message=f"ç”ŸæˆHTMLå¤±è´¥: {str(e)}"
        ))


# ==================== ä¸»æµç¨‹å‡½æ•° ====================
def _sanitize_filename(filename: str) -> str:
    """
    æ¸…ç†æ–‡ä»¶åï¼Œç§»é™¤éæ³•å­—ç¬¦
    
    Args:
        filename: åŸå§‹æ–‡ä»¶å
        
    Returns:
        æ¸…ç†åçš„æ–‡ä»¶å
    """
    # ç§»é™¤æˆ–æ›¿æ¢æ–‡ä»¶ç³»ç»Ÿä¸­çš„éæ³•å­—ç¬¦
    illegal_chars = ['/', '\\', ':', '*', '?', '"', '<', '>', '|']
    for char in illegal_chars:
        filename = filename.replace(char, '_')
    # ç§»é™¤ .adoc åç¼€ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
    if filename.lower().endswith('.adoc'):
        filename = filename[:-5]
    # ç§»é™¤é¦–å°¾ç©ºæ ¼å’Œç‚¹
    filename = filename.strip(' .')
    # å¦‚æœä¸ºç©ºï¼Œä½¿ç”¨é»˜è®¤åç§°
    if not filename:
        filename = 'æœªå‘½åæ–‡æ¡£'
    # é™åˆ¶æ–‡ä»¶åé•¿åº¦
    if len(filename) > 200:
        filename = filename[:200]
    return filename


def _get_document_title_from_mainsite(mainsite_content: Dict[str, Any]) -> str:
    """
    ä»mainsite_contentä¸­æå–æ–‡æ¡£æ ‡é¢˜
    
    Args:
        mainsite_content: mainsiteå†…å®¹å­—å…¸
        
    Returns:
        æ–‡æ¡£æ ‡é¢˜ï¼Œå¦‚æœæ— æ³•è·å–åˆ™è¿”å›é»˜è®¤å€¼
    """
    try:
        if 'dentryInfo' in mainsite_content and 'data' in mainsite_content['dentryInfo']:
            title = mainsite_content['dentryInfo']['data'].get('name')
            if title:
                return title
    except (KeyError, TypeError):
        pass
    return 'é’‰é’‰æ–‡æ¡£'


def _save_json_file(output_dir: Path, filename: str, data: Dict[str, Any]) -> None:
    """ä¿å­˜JSONæ–‡ä»¶"""
    file_path = output_dir / filename
    with open(file_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)


def _save_html_file(output_dir: Path, filename: str, content: str) -> None:
    """ä¿å­˜HTMLæ–‡ä»¶"""
    file_path = output_dir / filename
    with open(file_path, 'w', encoding='utf-8') as f:
        f.write(content)


async def get_complete_document_data(
    url_or_node_id: str,
    cookie: str,
    save_files: bool = True,
    output_dir: Optional[str] = None
) -> DocumentResult:
    """
    å®Œæ•´è·å–é’‰é’‰æ–‡æ¡£æ•°æ®çš„æµç¨‹
    
    Args:
        url_or_node_id: é’‰é’‰æ–‡æ¡£URLæˆ–NODE_ID
        cookie: é’‰é’‰ç™»å½•Cookie
        save_files: æ˜¯å¦ä¿å­˜ä¸­é—´æ–‡ä»¶
        output_dir: è¾“å‡ºç›®å½•è·¯å¾„
        
    Returns:
        DocumentResultå¯¹è±¡ï¼ŒåŒ…å«è§£æç»“æœ
        
    Raises:
        McpError: å½“è§£æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯æ—¶
    """
    node_id = extract_node_id_from_url(url_or_node_id)
    
    # æ­¥éª¤1: GETè¯·æ±‚è·å–HTML
    html = await fetch_node_by_get(node_id, cookie)
    
    # æ­¥éª¤2: æå–JSON
    mainsite_content = extract_mainsite_content(html)
    
    # æ­¥éª¤2.5: ä»mainsite_contentä¸­æå–æ–‡æ¡£æ ‡é¢˜
    doc_title = _get_document_title_from_mainsite(mainsite_content)
    
    # æ­¥éª¤2.6: å¦‚æœä¿å­˜æ–‡ä»¶ï¼Œåˆ›å»ºä»¥æ ‡é¢˜å‘½åçš„æ–‡ä»¶å¤¹
    if save_files:
        # æ¸…ç†æ ‡é¢˜ä½œä¸ºæ–‡ä»¶å¤¹å
        folder_name = _sanitize_filename(doc_title)
        
        # ç¡®å®šåŸºç¡€è¾“å‡ºç›®å½•
        if not output_dir:
            # é»˜è®¤è¾“å‡ºç›®å½•ä¸º ~/Documents/cursor-mcp/dingDoc
            base_dir = os.path.expanduser("~/Documents/cursor-mcp/dingDoc")
        else:
            base_dir = output_dir
        
        # åˆ›å»ºä»¥æ–‡æ¡£æ ‡é¢˜å‘½åçš„æ–‡ä»¶å¤¹
        output_path = Path(base_dir) / folder_name
        output_path.mkdir(parents=True, exist_ok=True)
    else:
        output_path = None
    
    if save_files and output_path:
        _save_json_file(output_path, f'{node_id}_mainsite.json', mainsite_content)
    
    # æ­¥éª¤3: æå–dentryKey
    dentry_key = extract_dentry_key(mainsite_content)
    
    # æ­¥éª¤4: POSTè¯·æ±‚è·å–æ–‡æ¡£æ•°æ®
    document_data = await fetch_document_data(cookie, dentry_key)
    
    if save_files and output_path:
        _save_json_file(output_path, f'{node_id}_document.json', document_data)
    
    # æ­¥éª¤5: æå–å†…å®¹
    content = extract_document_content(document_data)
    
    html_content = None
    image_url_map = None
    if content:
        if save_files and output_path:
            _save_json_file(output_path, f'{node_id}_content.json', content)
        
        # æ­¥éª¤5.5: æ”¶é›†å¹¶ä¸‹è½½æ‰€æœ‰å›¾ç‰‡
        if save_files and output_path:
            image_urls = collect_image_urls(content)
            if image_urls:
                image_url_map = {}
                # æ‰¹é‡ä¸‹è½½å›¾ç‰‡
                download_tasks = [
                    download_image(url, cookie, output_path) 
                    for url in image_urls
                ]
                results = await asyncio.gather(*download_tasks, return_exceptions=True)
                
                # æ„å»ºURLåˆ°æœ¬åœ°è·¯å¾„çš„æ˜ å°„
                for url, result in zip(image_urls, results):
                    if result and not isinstance(result, Exception):
                        image_url_map[url] = result
        
        # æ­¥éª¤6: ç”ŸæˆHTMLï¼ˆä½¿ç”¨ä»mainsiteä¸­è·å–çš„æ ‡é¢˜ï¼‰
        html_content = generate_html_from_content(content, doc_title, image_url_map)
        
        if save_files and html_content and output_path:
            _save_html_file(output_path, f'{node_id}.html', html_content)
    
    return DocumentResult(
        node_id=node_id,
        dentry_key=dentry_key,
        mainsite_content=mainsite_content,
        document_data=document_data,
        content=content,
        html=html_content,
        output_dir=str(output_path) if output_path else None
    )


async def serve() -> None:
    """è¿è¡Œé’‰é’‰æ–‡æ¡£è§£æMCPæœåŠ¡å™¨"""
    server = Server("mcp-dingtalk-doc")
    
    @server.list_tools()
    async def list_tools() -> list[Tool]:
        return [
            Tool(
                name="parse_document",
                description="è§£æé’‰é’‰æ–‡æ¡£ï¼Œæå–å†…å®¹å¹¶ç”ŸæˆHTMLæ–‡ä»¶",
                inputSchema=DingTalkDocRequest.model_json_schema(),
            ),
            Tool(
                name="get_html",
                description="å¿«é€Ÿè·å–é’‰é’‰æ–‡æ¡£çš„HTMLå†…å®¹ï¼ˆä¸ä¿å­˜æ–‡ä»¶ï¼‰",
                inputSchema=DingTalkDocParseRequest.model_json_schema(),
            )
        ]
    
    @server.list_prompts()
    async def list_prompts() -> list[Prompt]:
        return [
            Prompt(
                name="parse_document",
                description="è§£æé’‰é’‰æ–‡æ¡£å¹¶ç”ŸæˆHTML",
                arguments=[
                    PromptArgument(
                        name="url_or_node_id",
                        description="é’‰é’‰æ–‡æ¡£URLæˆ–NODE_ID",
                        required=True
                    ),
                    PromptArgument(
                        name="cookie",
                        description="é’‰é’‰Cookieï¼ˆå¯é€‰ï¼‰",
                        required=False
                    )
                ],
            )
        ]
    
    @server.call_tool()
    async def call_tool(name: str, arguments: dict) -> list[TextContent]:
        if name == "parse_document":
            try:
                args = DingTalkDocRequest(**arguments)
            except ValueError as e:
                raise McpError(ErrorData(code=INVALID_PARAMS, message=str(e)))
            
            cookie = check_cookie(args.cookie)
            
            try:
                result = await get_complete_document_data(
                    args.url_or_node_id,
                    cookie,
                    args.save_files,
                    args.output_dir
                )
                
                output = [f"âœ… é’‰é’‰æ–‡æ¡£è§£ææˆåŠŸï¼"]
                output.append(f"\nğŸ“Œ èŠ‚ç‚¹ID: {result.node_id}")
                output.append(f"ğŸ”‘ Dentry Key: {result.dentry_key}")
                
                if result.document_data:
                    doc_info = result.document_data.get('data', {}).get('fileMetaInfo', {})
                    output.append(f"ğŸ“„ æ–‡æ¡£åç§°: {doc_info.get('name', 'æœªçŸ¥')}")
                    output.append(f"ğŸ“ æ–‡æ¡£ç±»å‹: {doc_info.get('type', 'æœªçŸ¥')}")
                
                if result.content:
                    output.append(f"\nâœ… å†…å®¹æå–æˆåŠŸ")
                    parts_count = len(result.content.get('parts', {}))
                    output.append(f"   - Partsæ•°é‡: {parts_count}")
                
                if result.html:
                    output.append(f"\nâœ… HTMLç”ŸæˆæˆåŠŸ")
                
                if result.output_dir:
                    output.append(f"\nğŸ“ è¾“å‡ºç›®å½•: {result.output_dir}")
                    output.append(f"   - {result.node_id}_mainsite.json")
                    output.append(f"   - {result.node_id}_document.json")
                    if result.content:
                        output.append(f"   - {result.node_id}_content.json")
                    if result.html:
                        output.append(f"   - {result.node_id}.html")
                
                return [TextContent(type="text", text="\n".join(output))]
                
            except McpError:
                raise
            except Exception as e:
                raise McpError(ErrorData(
                    code=INTERNAL_ERROR,
                    message=f"æ–‡æ¡£è§£æå¤±è´¥: {str(e)}"
                ))
        
        elif name == "get_html":
            try:
                args = DingTalkDocParseRequest(**arguments)
            except ValueError as e:
                raise McpError(ErrorData(code=INVALID_PARAMS, message=str(e)))
            
            cookie = check_cookie(args.cookie)
            
            try:
                result = await get_complete_document_data(
                    args.url_or_node_id,
                    cookie,
                    save_files=False
                )
                
                if result.html:
                    doc_name = result.document_data.get('data', {}).get('fileMetaInfo', {}).get('name', 'æœªçŸ¥') if result.document_data else 'æœªçŸ¥'
                    output = [f"âœ… HTMLç”ŸæˆæˆåŠŸ\n"]
                    output.append(f"æ–‡æ¡£: {doc_name}\n")
                    output.append("--- HTML å†…å®¹ ---\n")
                    output.append(result.html)
                    return [TextContent(type="text", text="\n".join(output))]
                else:
                    return [TextContent(type="text", text="âš ï¸ æ— æ³•æå–æ–‡æ¡£å†…å®¹ï¼ˆå¯èƒ½æ˜¯OSSåŠ å¯†ï¼‰")]
                    
            except McpError:
                raise
            except Exception as e:
                raise McpError(ErrorData(
                    code=INTERNAL_ERROR,
                    message=f"æ–‡æ¡£è§£æå¤±è´¥: {str(e)}"
                ))
        
        else:
            raise McpError(ErrorData(
                code=INVALID_PARAMS,
                message=f"æœªçŸ¥å·¥å…·: {name}"
            ))
    
    @server.get_prompt()
    async def get_prompt(name: str, arguments: dict | None) -> GetPromptResult:
        if not arguments or "url_or_node_id" not in arguments:
            raise McpError(ErrorData(
                code=INVALID_PARAMS,
                message="å¿…é¡»æä¾›url_or_node_idå‚æ•°"
            ))
        
        url_or_node_id = arguments["url_or_node_id"]
        cookie = check_cookie(arguments.get("cookie"))
        
        try:
            result = await get_complete_document_data(url_or_node_id, cookie, save_files=False)
            
            output = [f"âœ… é’‰é’‰æ–‡æ¡£è§£ææˆåŠŸ"]
            output.append(f"\nèŠ‚ç‚¹ID: {result.node_id}")
            
            if result.document_data:
                doc_info = result.document_data.get('data', {}).get('fileMetaInfo', {})
                output.append(f"æ–‡æ¡£åç§°: {doc_info.get('name', 'æœªçŸ¥')}")
            
            if result.html:
                output.append(f"\nHTMLå·²ç”Ÿæˆ")
            
            return GetPromptResult(
                description="é’‰é’‰æ–‡æ¡£è§£æç»“æœ",
                messages=[
                    PromptMessage(
                        role="user",
                        content=TextContent(type="text", text="\n".join(output))
                    )
                ]
            )
            
        except McpError as e:
            return GetPromptResult(
                description="è§£æå¤±è´¥",
                messages=[
                    PromptMessage(
                        role="user",
                        content=TextContent(type="text", text=f"é”™è¯¯: {e.error.message}")
                    )
                ]
            )
    
    options = server.create_initialization_options()
    async with stdio_server() as (read_stream, write_stream):
        await server.run(read_stream, write_stream, options, raise_exceptions=True)


def main():
    """ä¸»å…¥å£å‡½æ•°"""
    asyncio.run(serve())


if __name__ == "__main__":
    main()

